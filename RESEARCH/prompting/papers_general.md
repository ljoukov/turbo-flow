# Promptable Generative Models in Physics (with Emphasis on CFD)

## a. Master Table of Promptable Physics Models

| **Model / Citation**                                                                                                                                                                                                                                    | **Physics Domain**                 | **Model Family**                     | **Prompt/Conditioning Interface**                               | **What Prompt Controls**                       | **Output Type**                             | **Reported Accuracy vs. Baseline**                                                                                                                                                                                                                                                                                                                                                                  | **Code Availability / License**                                                                                                                                                                                                                  |
| ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------- | ------------------------------------ | --------------------------------------------------------------- | ---------------------------------------------- | ------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| **CoNFiLD** (Du _et al._, 2024 ([arxiv.org](https://arxiv.org/html/2403.05940v2#:~:text=This%20study%20introduces%20the%20Conditional,The)))                                                                                                            | Fluid dynamics (turbulence)        | Latent diffusion + neural field      | Spatial field encodings (neural implicit field)                 | Geometry & partial flow data (e.g. sensors)    | Spatiotemporal flow field (3D)              | Zero-shot reconstruction & super-res match DNS; robust to irregular domains ([arxiv.org](https://arxiv.org/html/2403.05940v2#:~:text=conditional%20neural%20field%20encoding%20with,transformative%20potential%20in%20the%20domain)) ([arxiv.org](https://arxiv.org/html/2403.05940v2#:~:text=turbulence%20under%20varied%20conditions,broader%20modeling%20of%20spatiotemporal%20dynamics))        | Open-source (GitHub, Apache-2.0) ([github.com](https://github.com/jx-wang-s-group/CoNFiLD#:~:text=Field%20Latent%20Diffusion%20Model%20Generating,2.0%20license))                                                                                |
| **CoNFiLD-inlet** (Liu _et al._, 2024)                                                                                                                                                                                                                  | Fluid dynamics (inflow turbulence) | Latent diffusion + neural field      | Parameter vector (Reynolds number) + spatial field              | Turbulence inflow condition spectrum           | Stochastic inflow velocity field            | Generalizes across Re<sub>τ</sub> 10^3–10^4 without retraining ([arxiv.org](https://arxiv.org/abs/2411.14378#:~:text=novel%20DL,versatile%20solution%20for%20inflow%20turbulence)); high fidelity vs DNS/LES                                                                                                                                                                                        | Expected open-source (extension of CoNFiLD)                                                                                                                                                                                                      |
| **GenCFD** (Molinaro _et al._, 2024 ([arxiv.org](https://arxiv.org/html/2409.18359v2#:~:text=fluid%20flows,of%20relevant%20statistical%20quantities%20of)))                                                                                             | Fluid dynamics (chaotic flows)     | Conditional score-based diffusion    | Full initial state field (e.g. velocity grid)                   | Future flow evolution (stochastic)             | Velocity field realization (3D/2D)          | Indistinguishable from DNS visually; ~10× lower error in variance vs FNO baseline ([arxiv.org](https://arxiv.org/html/2409.18359v2#:~:text=match%20at%20L362%20target%20distribution,of%20magnitude%20more%20accurate%20at)) ([arxiv.org](https://arxiv.org/html/2409.18359v2#:~:text=target%20distribution%20and%20the%20conditional,of%20magnitude%20more%20accurate%20at))                       | Open-source (GitHub, Apache-2.0) ([github.com](https://github.com/camlab-ethz/GenCFD#:~:text=License))                                                                                                                                           |
| **Morton et al. (2019)** ([ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/1912.06752#:~:text=The%20computational%20cost%20associated%20with,the%20corresponding%20computational%20fluid%20dynamics))                                           | Fluid dynamics (aero)              | Sequential generative RNN            | Parameter vector (flow conditions)                              | Entire flow simulation trajectory              | Time-series of flow fields (2D/3D)          | Captures local & global flow features over wide conditions; simulation ~1000× faster than CFD ([ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/1912.06752#:~:text=three,the%20corresponding%20computational%20fluid%20dynamics))                                                                                                                                                           | No public code (methodology paper)                                                                                                                                                                                                               |
| **FluidDiff** (Yang & Sommer, 2023 ([ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/2301.11661#:~:text=We%20propose%20a%20novel%20denoising,promising%20for%20investigation%20on%20new)))                                                      | Fluid dynamics (smoke)             | Denoising diffusion (DDPM)           | Initial state grid + time conditioning                          | Smoke plume at specified future time           | 2D scalar field (smoke density)             | Competitive with specialized simulators on smoke evolution ([ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/2301.11661#:~:text=fluid%20simulation%20data,new%20computational%20fluid%20dynamics%20methods)) ([ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/2301.11661#:~:text=the%20distribution%20of%20simulated%20training,new%20computational%20fluid%20dynamics%20methods)) | Not available (research prototype)                                                                                                                                                                                                               |
| **DiffFluid** (Luo _et al._, 2024 ([arxiv.org](https://arxiv.org/abs/2409.13665#:~:text=effective%20predictors%20of%20fluid%20dynamics,art%20performance%2C%20particularly%20in)))                                                                      | Fluid dynamics (various)           | Diffusion model + Transformer        | Image-like grid (geometry mask or coeff field) + metadata       | Steady-state or transient flow solution        | Field (pressure/velocity) on grid           | SOTA accuracy: e.g. ~45% error reduction on Navier–Stokes, 14% on Darcy vs previous best ([arxiv.org](https://arxiv.org/abs/2409.13665#:~:text=solutions,this%20https%20URL%20upon%20acceptance))                                                                                                                                                                                                   | Code to be released (planned open source)                                                                                                                                                                                                        |
| **DiffusionPDE** (Huang _et al._, 2024 ([arxiv.org](https://arxiv.org/html/2406.17763v2#:~:text=We%20introduce%20a%20general%20framework,range%20of%20PDEs%20under%20partial)))                                                                         | General PDE (multi-type)           | Conditional diffusion (latent)       | Sparse observations (sensor values); PDE equation as constraint | Full solution field & unknown coeffs           | Field (static or time-series)               | Outperforms neural operators on 5 PDEs under 1–3% data; matches full-data accuracy ([arxiv.org](https://arxiv.org/html/2406.17763v2#:~:text=We%20conduct%20extensive%20experiments%20to,9%29%2C%20suggesting)) ([arxiv.org](https://arxiv.org/html/2406.17763v2#:~:text=data%20and%20find%20subsequent%20solutions,trained%20generative%20network))                                                 | Open-source (GitHub, CC BY 4.0) ([github.com](https://github.com/jhhuangchloe/DiffusionPDE#:~:text=License))                                                                                                                                     |
| **CORAL** (Serrano _et al._, 2023 ([arxiv.org](https://arxiv.org/html/2306.07266#:~:text=limitations%2C%20we%20present%20CORAL%2C%20a,art)))                                                                                                            | General PDE (any geometry)         | Neural operator (implicit coord net) | Point coordinates + geometry ID (implicit)                      | Mapping of input function to output function   | Solution function (continuous latent)       | Handles non-convex domains; accuracy on par or better than FNO on irregular meshes ([arxiv.org](https://arxiv.org/html/2306.07266#:~:text=limitations%2C%20we%20present%20CORAL%2C%20a,art)) ([arxiv.org](https://arxiv.org/html/2306.07266#:~:text=spatio,art))                                                                                                                                    | Open-source (GitHub, MIT) ([github.com](https://github.com/LouisSerrano/coral#:~:text=))                                                                                                                                                         |
| **GAOT** (Wen _et al._, 2025 ([arxiv.org](https://arxiv.org/html/2505.18781v1#:~:text=proposing%20a%20geometry%20aware%20operator,on%20a%20large%20scale%20three)))                                                                                     | CFD (arbitrary domains)            | Graph attentional Transformer        | Mesh graph (nodes + geometry embedding)                         | Boundary geometry + inputs (BCs, forces)       | Field on mesh (any shape, 3D capable)       | Achieves best accuracy on 3D industrial CFD dataset; faster than prior GNNs ([arxiv.org](https://arxiv.org/html/2505.18781v1#:~:text=proposing%20a%20geometry%20aware%20operator,on%20a%20large%20scale%20three)) ([arxiv.org](https://arxiv.org/html/2505.18781v1#:~:text=inputs%20into%20a%20robust%20approximation,ethz%2FGAOT))                                                                 | Open-source (GitHub – camlab-ethz/GAOT, license TBA)                                                                                                                                                                                             |
| **PI-GANO** (Zhong & Meidani, 2024 ([arxiv.org](https://arxiv.org/html/2408.01600v1#:~:text=current%20physics,efficiency%20of%20the%20proposed%20method)))                                                                                              | Structural & fluid (design)        | Physics-informed DeepONet + PointNet | Param vector (material/flow params) + point-cloud geometry      | PDE parameter values & domain shape            | Solution field (mesh or grid)               | Solves parametric PDEs with no data; <5% error in stress fields across shapes (reported)                                                                                                                                                                                                                                                                                                            | Open-source (GitHub, MIT) ([github.com](https://github.com/WeihengZ/PI-GANO#:~:text=Skip%20to%20content%20WeihengZ%20%2F,GANO))                                                                                                                  |
| **Text2PDE** (Zhou _et al._, 2025 ([arxiv.org](https://arxiv.org/html/2410.01153#:~:text=temporal%20solution%20generation%20to%20mitigate,accurate%2C%20and%20usable%20physics%20simulator)))                                                           | Multi-physics (fluid, etc.)        | Latent diffusion (LDM)               | Natural language prompt (or initial field)                      | Complete simulation scenario (setup & physics) | Full PDE solution rollout (all time steps)  | Matches state-of-art solver accuracy on tested cases; 3B-param model scales well ([arxiv.org](https://arxiv.org/html/2410.01153#:~:text=conditioning%20solely%20on%20a%20text,solvers%20closer%20to%20practical%20use)) ([arxiv.org](https://arxiv.org/html/2410.01153#:~:text=generating%20physics%20simulations%2C%20paving%20the,solvers%20closer%20to%20practical%20use))                       | Open-source (GitHub, code+weights released) ([arxiv.org](https://arxiv.org/html/2410.01153#:~:text=and%20a%20more%20precise%20one,1%2Fldm_pdes)) ([arxiv.org](https://arxiv.org/html/2410.01153#:~:text=https%3A%2F%2Fgithub.com%2Fanthonyzhou)) |
| **FourCastNet** (Pathak _et al._, 2022)                                                                                                                                                                                                                 | Weather (global)                   | Fourier Neural Operator (AFNO)       | Initial weather state (ERA5 gridded data)                       | Earth’s atmospheric initial conditions         | Multi-step forecast (0–7 days)              | ~<2% error difference vs ECMWF at 5 days; 1 week forecast in 1–2 seconds ([docs.nvidia.com](https://docs.nvidia.com/deeplearning/modulus/modulus-sym/user_guide/neural_operators/fourcastnet.html#:~:text=predictions%20at%200,In%20the%20current)) ([www.huaweicloud.com](https://www.huaweicloud.com/intl/en-us/about/blogs/20230707.html#:~:text=times,Weather%20reduces%20them))                | Open-source (GitHub NVlabs, BSD-3 clause)                                                                                                                                                                                                        |
| **GraphCast** (Lam _et al._, 2023 ([deepmind.google](https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting#:~:text=In%20a%20paper%20published%20in,Range%20Weather%20Forecasts%20%28ECMWF))) | Weather (global)                   | Graph neural network (GNN)           | Spherical mesh graph (47M nodes) + meteorological data          | Earth initial conditions (all variables)       | Multi-step forecast (10 days)               | Outperforms ECMWF HRES: e.g. ~10–15% RMSE reduction on 5-day winds ([www.huaweicloud.com](https://www.huaweicloud.com/intl/en-us/about/blogs/20230707.html#:~:text=U10%2C%20the%203,53%2C%20respectively)); predicts extremes better                                                                                                                                                                | Open-source (GitHub DeepMind, Apache-2.0) ([github.com](https://github.com/google-deepmind/graphcast#:~:text=The%20Colab%20notebooks%20and%20the,2.0))                                                                                           |
| **Pangu-Weather** (Bi _et al._, 2023)                                                                                                                                                                                                                   | Weather (global)                   | 3D ConvNet (UNet) + Transformer      | Layers of 2D maps (pressure levels)                             | Earth initial conditions (global field)        | Multi-step forecast (10 days)               | Beats ECMWF: e.g. Z500 5-day RMSE 296.7 vs 333.7 (IFS) ([www.huaweicloud.com](https://www.huaweicloud.com/intl/en-us/about/blogs/20230707.html#:~:text=times,Weather%20reduces%20them)); better tropical cyclone tracks                                                                                                                                                                             | Closed source (Huawei internal)                                                                                                                                                                                                                  |
| **InverseDiffusion (Mechanics)** (Dasgupta _et al._, 2024 ([arxiv.org](https://arxiv.org/html/2406.13154v1#:~:text=We%20propose%20a%20framework%20to,Monte%20Carlo%20scheme%20based%20on)))                                                             | Solid mechanics (elastography)     | Conditional score-based diffusion    | Sensing data (displacement fields, etc.)                        | Spatial material property distribution         | Material field (Young’s modulus map)        | Solves high-dim inverse problems with complex noise; recovers heterogeneities no classical method can ([arxiv.org](https://arxiv.org/html/2406.13154v1#:~:text=based%20diffusion%20models%20to%20solve,Monte%20Carlo%20scheme%20based%20on)) ([arxiv.org](https://arxiv.org/html/2406.13154v1#:~:text=forward%20model,approach%20can%20handle%20different%20measurement))                           | Code released (upon acceptance, license N/A)                                                                                                                                                                                                     |
| **Parnassus-Flow** (Dreyer _et al._, 2025 ([arxiv.org](https://arxiv.org/html/2503.19981v1#:~:text=We%20extend%20the%20Particle,compatible.%20Using%20a)))                                                                                              | High-energy physics (LHC)          | Normalizing Flow + Diffusion         | Particle list (truth-level event particles)                     | Detector response & reconstruction             | Full event: list of reconstructed particles | >Delphes fast-sim accuracy on jets/events; generalizes to new physics processes ([arxiv.org](https://arxiv.org/html/2503.19981v1#:~:text=normalizing%20flows%20and%20diffusion%20models%2C,the%20standard%2C%20public%20tool%20Delphes))                                                                                                                                                            | Open-source (GitHub, license N/A) ([arxiv.org](https://arxiv.org/html/2503.19981v1#:~:text=The%20code%20for%20this%20paper,org%2Frecords%2F15083495))                                                                                            |
| **Airfoil-Diffusion** (Werhahn _et al._, 2023 ([arxiv.org](https://arxiv.org/html/2312.05320v1#:~:text=simulations,distributions%20of%20uncertainties%20rather%20than)))                                                                                | CFD (aerodynamics)                 | Denoising diffusion (DDPM)           | Shape parametrization + flow conditions (Re, angle)             | Turbulent flow around airfoil                  | Steady 2D flow field (pressure/velocity)    | Captures full solution distribution; ~20% lower error than Bayesian NNs on drag, with uncertainty bands ([arxiv.org](https://arxiv.org/html/2312.05320v1#:~:text=learning%20objective,The%20source%20code%20and%20datasets)) ([arxiv.org](https://arxiv.org/html/2312.05320v1#:~:text=The%20present%20study%20makes%20a,DDPMs%20outperform%20the%20other%20methods))                                | Open-source (GitHub TUM-PBS, MIT) ([arxiv.org](https://arxiv.org/html/2312.05320v1#:~:text=samples%20from%20the%20distribution%20of,Prediction))                                                                                                 |
| **GNO-Airfoils** (Belbute-Peres _et al._, 2023)                                                                                                                                                                                                         | CFD (aeroacoustics)                | Graph Neural Network (GNN)           | Discrete airfoil surface mesh + flow conditions                 | Airfoil shape & state (flow velocity)          | Steady flow & noise metrics                 | Predicted lift/drag within 5% of CFD; multi-objective shape optimization achieved (qualitative)                                                                                                                                                                                                                                                                                                     | Code available (upon request, proprietary)                                                                                                                                                                                                       |

_(Table legend: Each row describes a model, its domain, architecture, how it accepts prompts/conditions, what the prompt controls at inference, the output produced, accuracy vs conventional baselines, and code availability. “Baseline” refers to state-of-the-art numerical solvers or prior ML models.)_

## b. How Each Promptable Model Works (Technical Explanations)

### Generative Surrogates for Fluid Dynamics

**CoNFiLD (Conditional Neural Field Latent Diffusion)** – CoNFiLD employs a _neural field_ to encode geometry or partial observations into a latent condition for a diffusion model ([arxiv.org](https://arxiv.org/html/2403.05940v2#:~:text=conditional%20neural%20field%20encoding%20with,transformative%20potential%20in%20the%20domain)). At inference, one can provide, for example, a sparse set of sensor readings or a coarse flow field along with the domain shape, and CoNFiLD performs **Bayesian conditional sampling** to generate full 3D turbulent flow fields consistent with those inputs ([arxiv.org](https://arxiv.org/html/2403.05940v2#:~:text=turbulence%20under%20varied%20conditions,broader%20modeling%20of%20spatiotemporal%20dynamics)). Technically, an implicit neural representation (coordinate-based MLP) first encodes the flow condition on an irregular geometry; a 3D latent diffusion model then iteratively denoises random noise into a realistic flow field conditioned on that encoding ([arxiv.org](https://arxiv.org/html/2403.05940v2#:~:text=This%20study%20introduces%20the%20Conditional,The)) ([arxiv.org](https://arxiv.org/html/2403.05940v2#:~:text=conditional%20neural%20field%20encoding%20with,transformative%20potential%20in%20the%20domain)). This allows _zero-shot generalization_: without retraining, a single CoNFiLD model can handle different domains (pipes, channels, hills) and tasks like flow reconstruction from sparse data or super-resolution of a coarse simulation ([arxiv.org](https://arxiv.org/html/2403.05940v2#:~:text=conditional%20neural%20field%20encoding%20with,transformative%20potential%20in%20the%20domain)). The model yields diverse plausible flow realizations capturing turbulence stochasticity, all while being memory-efficient on GPU due to the latent-space diffusion.

**CoNFiLD-inlet** – A specialized variant of CoNFiLD targeting **turbulence inflow generation**. It conditions a latent diffusion model on a _Reynolds number parameter_ and a neural field representation of the inflow cross-section ([arxiv.org](https://arxiv.org/abs/2411.14378#:~:text=novel%20DL,versatile%20solution%20for%20inflow%20turbulence)). By training across a range of Reynolds numbers (10^3–10^4), CoNFiLD-inlet can synthesize physically realistic turbulent inflow boundary conditions for CFD without separate runs for each flow regime ([arxiv.org](https://arxiv.org/abs/2411.14378#:~:text=novel%20DL,versatile%20solution%20for%20inflow%20turbulence)). The prompt in this case is a dimensionless number (and possibly an initial random seed), and the output is a 3D turbulent velocity field at the inlet plane. The method avoids traditional precursor simulations by generating inflow turbulence on-the-fly, and achieves high fidelity and long-term stability in downstream LES/DNS tests (matching turbulence statistics of ground-truth inflows). It requires no retraining when the user **prompts** a new Reynolds number within its trained range, illustrating prompt-conditioned generalization in fluid simulation.

**GenCFD** – GenCFD is a _conditional score-based diffusion model_ for chaotic fluid dynamics ([arxiv.org](https://arxiv.org/html/2409.18359v2#:~:text=fluid%20flows,of%20relevant%20statistical%20quantities%20of)). It treats the evolution of a turbulent flow as a probabilistic generative process: given an initial condition (e.g. velocity field at t=0) as the prompt, GenCFD’s U-Net/ViT-based denoiser network iteratively refines random noise into a physically plausible flow field at a later time ([arxiv.org](https://arxiv.org/html/2409.18359v2#:~:text=match%20at%20L307%20the%20other,red%20arrows%29%20to)) ([arxiv.org](https://arxiv.org/html/2409.18359v2#:~:text=the%20other%20hand%2C%20our%20method,red%20arrows%29%20to)). Essentially, it learns the conditional distribution $p(\text{flow at time }T \mid \text{initial state})$ via diffusion. At inference, one draws multiple samples to represent possible chaotic evolutions. Notably, GenCFD captures _uncertainty and variability_ of turbulence that deterministic neural surrogates miss ([arxiv.org](https://arxiv.org/html/2409.18359v2#:~:text=fluid%20flows,of%20relevant%20statistical%20quantities%20of)) ([arxiv.org](https://arxiv.org/html/2409.18359v2#:~:text=through%20extensive%20numerical%20experiments%2C%20that,is%20several%20orders%20of%20magnitude)). Technically, it uses an Ito reverse SDE (score-based model) conditioned on the input field, with a **denoiser network (UViT)** trained on high-fidelity simulation data ([arxiv.org](https://arxiv.org/html/2409.18359v2#:~:text=model%2C%20which%20is%20also%20the,networks%20that%20are%20trained%20to)) ([arxiv.org](https://arxiv.org/html/2409.18359v2#:~:text=transform%20any%20to%20a%20noisy,cylindrical%20shear%20flow%20dataset%3A%20individual)). This approach produces flow realizations that are visually and statistically indistinguishable from DNS, outperforming baseline neural operators in matching energy spectra and variance ([arxiv.org](https://arxiv.org/html/2409.18359v2#:~:text=,quality%20of%20GenCFD%20is%20further)) ([arxiv.org](https://arxiv.org/html/2409.18359v2#:~:text=Moreover%2C%20GenCFD%20excels%20at%20approximating,In%20particular%2C%20the%20variance%20of)). The open-source code provides a script to load a pretrained GenCFD model and sample a velocity field given any new initial condition (the _prompt_). For example, users can run a provided script to generate multiple 3D Taylor–Green vortex decays from one initial velocity field, obtaining an ensemble of outcomes.

**Morton et al. (2019) – Parameter-Conditioned Sequential Model** – This work introduced a **sequence-generating network** (an RNN-based auto-regressive model) conditioned on simulation parameters ([ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/1912.06752#:~:text=The%20computational%20cost%20associated%20with,the%20corresponding%20computational%20fluid%20dynamics)). The network was trained on many CFD simulations varying a few parameters (like inlet velocity or shape), learning to produce the next time-step given the past. At inference, a user can input a new set of parameters (within the training range) as a prompt, and the model rolls out an entire flow trajectory step-by-step. The prompting mechanism here is straightforward: a vector of nondimensional parameters is fed into the model’s initial hidden state (or concatenated to inputs at each step) to modulate the dynamics. Technically, Morton’s model used LSTM layers that consume the previous flow state and output the next state, with an additional encoder that processes the parameter vector ([ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/1912.06752#:~:text=neural%20network%20models%20capable%20of,corresponding%20computational%20fluid%20dynamics%20simulations)). This enables **parameterized simulation** – e.g. one network can simulate airflow at various angles of attack or Reynolds numbers without retraining. The results showed the RNN capturing both local and global flow features across a wide range of conditions ([ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/1912.06752#:~:text=upon%20concepts%20from%20generative%20modeling%2C,the%20corresponding%20computational%20fluid%20dynamics)). Moreover, it achieved orders-of-magnitude speed-ups (1000× faster) compared to running a new CFD solver for each parameter set ([ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/1912.06752#:~:text=three,the%20corresponding%20computational%20fluid%20dynamics)), albeit with some accuracy trade-offs. This model exemplifies promptable surrogate modeling before diffusion models became popular.

**FluidDiff** – FluidDiff is a denoising diffusion model designed for **nonlinear fluid flow prediction** ([ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/2301.11661#:~:text=We%20propose%20a%20novel%20denoising,promising%20for%20investigation%20on%20new)). It is trained on a dataset of smoke plume simulations: given an initial smoke distribution, predict the density field at a future time. The model conditions on the initial field (concatenated as an input channel) and time-step, and then uses Langevin sampling to generate the future state ([ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/2301.11661#:~:text=fluid%20fields%20named%20FluidDiff,promising%20for%20investigation%20on%20new)) ([ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/2301.11661#:~:text=prediction%20model%20FluidDiff%3B%202,Section%205%20shows%20the)). During inference, the user supplies a **prompt** consisting of the starting fluid state and a target time (e.g. “predict 10 seconds later”). The diffusion model (a U-Net) then produces a physically plausible smoke density field for that time. Key technical aspects include an annealed diffusion process in pixel-space and a loss that encourages matching the true distribution of simulations rather than a single deterministic outcome ([ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/2301.11661#:~:text=and%20then%20Langevin%20sampling%20is,new%20computational%20fluid%20dynamics%20methods)). FluidDiff requires retraining for different types of flow or different physics, but within its domain (buoyant smoke) it generalizes to new plumes or obstacle configurations not seen in training. It achieved accuracy comparable to other deep learning simulators (like CNN-based fluid predictors) on 2D smoke rising scenarios ([ar5iv.labs.arxiv.org](https://ar5iv.labs.arxiv.org/html/2301.11661#:~:text=fluid%20simulation%20data,new%20computational%20fluid%20dynamics%20methods)), with the added benefit of sampling multiple outcomes (important for chaotic flows). The prompting mechanism (initial condition + time) is handled by encoding the time as an additional input to the network, allowing one trained model to produce variable-length rollouts.

**DiffFluid** – DiffFluid showcases that _plain diffusion models with Transformers_ can serve as effective physics predictors ([arxiv.org](https://arxiv.org/abs/2409.13665#:~:text=,precision)). The architecture is essentially a latent diffusion model where the U-Net backbone is augmented with Vision Transformer blocks for increased capacity. The condition (prompt) is provided as an “input image” representing the scenario: e.g. for Darcy flow, a permeability field image; for airfoil flow, an image mask of the airfoil shape plus flow parameters encoded in channels ([arxiv.org](https://arxiv.org/abs/2409.13665#:~:text=effective%20predictors%20of%20fluid%20dynamics,related%20benchmarks%2C%20our)). The model treats solving a PDE like _image-to-image translation_ ([arxiv.org](https://arxiv.org/abs/2409.13665#:~:text=that%20depend%20on%20complex%20architectures,dynamics%2C%20with%20a%20relative%20precision)): it diffuses the output field and denoises conditioned on the input field. In practice, a user can **prompt** the model with a new geometry or coefficient field by feeding in the corresponding grid (e.g. a bitmap of a new airfoil), and the diffusion model will generate the solution (pressure/velocity field) for that input. The training dataset comprises many random instances (shapes or coefficients) paired with solutions, enabling the model to cover a broad distribution. DiffFluid achieved state-of-the-art accuracy on several benchmarks, improving solution error metrics by 10–45% over prior neural operators ([arxiv.org](https://arxiv.org/abs/2409.13665#:~:text=solutions,this%20https%20URL%20upon%20acceptance)). For example, given a new airfoil shape, DiffFluid’s one-shot prediction of the flow was more accurate than a specialized FNO baseline while using a simpler “vanilla” diffusion+Transformer approach. The technical takeaway is that large generic architectures can be promptable surrogates if trained on diverse data; DiffFluid’s Transformer attentional layers help capture both local and global flow features automatically, rather than requiring problem-specific architecture.

**Airfoil-Diffusion (Werhahn et al. 2023)** – This model applies a DDPM (denoising diffusion probabilistic model) as an **uncertainty-aware surrogate** for 2D airfoil flows ([arxiv.org](https://arxiv.org/html/2312.05320v1#:~:text=simulations,distributions%20of%20uncertainties%20rather%20than)). The conditioning inputs are (i) a shape descriptor (e.g. a set of parameters for the airfoil geometry or a signed distance image of the shape), and (ii) flow parameters like Reynolds number and angle of attack ([arxiv.org](https://arxiv.org/html/2312.05320v1#:~:text=simulations,distributions%20of%20uncertainties%20rather%20than)). The diffusion model is trained on a high-fidelity CFD dataset of various airfoils and flow conditions, learning to produce the steady-state flow field (pressure and velocity distribution) as an output. At inference, one provides a new airfoil shape plus flight conditions as the prompt – the model then samples possible flow fields. Because it’s probabilistic, repeated sampling yields a distribution of solutions, reflecting uncertainties (e.g. turbulence model uncertainties or numerical errors). Technically, the network is a U-Net that takes as input a channel-wise concatenation of the airfoil mask and parameter values, and outputs flow variables; it’s trained to match the CFD data distribution via a diffusion loss ([arxiv.org](https://arxiv.org/html/2312.05320v1#:~:text=topic%20of%20growing%20interest,DDPMs%20is%20also%20compared%20with)) ([arxiv.org](https://arxiv.org/html/2312.05320v1#:~:text=learning%20objective,The%20source%20code%20and%20datasets)). The authors demonstrate that this approach not only predicts mean quantities like lift and drag close to CFD results, but also produces realistic random perturbations consistent with physical variability ([arxiv.org](https://arxiv.org/html/2312.05320v1#:~:text=learning%20objective,The%20source%20code%20and%20datasets)). In fact, it outperformed baselines like Bayesian neural networks in both accuracy and calibration of uncertainty ([arxiv.org](https://arxiv.org/html/2312.05320v1#:~:text=learning%20objective,The%20source%20code%20and%20datasets)) ([arxiv.org](https://arxiv.org/html/2312.05320v1#:~:text=The%20present%20study%20makes%20a,DDPMs%20outperform%20the%20other%20methods)). The prompting mechanism is straightforward: change the input shape or parameters, and the same model generates a new flow – enabling rapid exploration of design spaces. The code is available, allowing users to plug in their own airfoil coordinates and get a flow prediction with error bars.

### Neural Operators and Physics-Informed Models with Geometry Conditioning

**DiffusionPDE** – DiffusionPDE is a _general PDE solver via generative modeling_ that can fill in missing information while satisfying physics ([arxiv.org](https://arxiv.org/html/2406.17763v2#:~:text=work%2C%20we%20propose%20DiffusionPDE%20that,PDE)) ([arxiv.org](https://arxiv.org/html/2406.17763v2#:~:text=We%20present%20a%20comprehensive%20framework%2C,However%2C%20we%20uniquely%20guide%20this)). It uses a latent diffusion model trained on joint distributions of PDE coefficient fields and solution fields ([arxiv.org](https://arxiv.org/html/2406.17763v2#:~:text=work%2C%20we%20propose%20DiffusionPDE%20that,PDE)) ([arxiv.org](https://arxiv.org/html/2406.17763v2#:~:text=data%20and%20find%20subsequent%20solutions,trained%20generative%20network)). At inference time, the user provides a **partial prompt**: for example, a few sensor measurements of the solution, or an incomplete description of the coefficient (material property) field ([arxiv.org](https://arxiv.org/html/2406.17763v2#:~:text=scenarios%20where%20we%20do%20not,art%20methods%20for%20both)) ([arxiv.org](https://arxiv.org/html/2406.17763v2#:~:text=We%20present%20a%20comprehensive%20framework%2C,However%2C%20we%20uniquely%20guide%20this)). Starting from random latent variables, the model then performs conditioned denoising steps guided by the observed data and the known PDE (the PDE residual is enforced at each step) ([arxiv.org](https://arxiv.org/html/2406.17763v2#:~:text=data%20and%20find%20subsequent%20solutions,trained%20generative%20network)) ([arxiv.org](https://arxiv.org/html/2406.17763v2#:~:text=effectively%20managing%20the%20uncertainty%20and,trained%20generative%20network)). The result is a _sample from the posterior_ of solutions that both agree with the sparse observations and satisfy the PDE. This approach effectively handles scenarios where classical solvers fail due to incomplete inputs. For instance, given only 5 sensor readings from a Burgers’ equation solution, DiffusionPDE was able to reconstruct the entire spatiotemporal field accurately ([arxiv.org](https://arxiv.org/html/2406.17763v2#:~:text=temporal%20PDEs%2C%20including%20Darcy%20Flow%2C,world%20applications)) ([arxiv.org](https://arxiv.org/html/2406.17763v2#:~:text=comparable%20results%20with%20full%20observations,world%20applications)). Under the hood, the model uses a UNet in latent space (for efficiency) and encodes conditions by concatenation and soft constraints: observed points are encoded into an “observation mask” that is fed in as part of the input at each denoising step ([arxiv.org](https://arxiv.org/html/2406.17763v2#:~:text=data%20and%20find%20subsequent%20solutions,trained%20generative%20network)) ([arxiv.org](https://arxiv.org/html/2406.17763v2#:~:text=effectively%20managing%20the%20uncertainty%20and,trained%20generative%20network)). Because it is generative, it can provide many possible completions (useful for uncertainty quantification). DiffusionPDE significantly outperformed state-of-the-art operator networks and PINNs on benchmark tasks when only 1–3% of data was available ([arxiv.org](https://arxiv.org/html/2406.17763v2#:~:text=We%20conduct%20extensive%20experiments%20to,9%29%2C%20suggesting)). The **prompt** is extremely flexible: any pattern of known points or subdomains can be supplied without retraining, and the single trained model seamlessly adapts to it ([arxiv.org](https://arxiv.org/html/2406.17763v2#:~:text=following%20standard%20diffusion%20models%20,trained%20generative%20network)). This marks a step toward _universally promptable solvers_ that integrate data and physics.

**CORAL (Coordinate-based Operator Learning)** – CORAL is an operator learning framework that leverages **implicit neural representations** (INR) to handle arbitrary geometries ([arxiv.org](https://arxiv.org/html/2306.07266#:~:text=results%20they%20still%20face%20challenges,well%20in%20both%20convex%20and)) ([arxiv.org](https://arxiv.org/html/2306.07266#:~:text=To%20overcome%20these%20limitations%2C%20there,dynamics%20forecasting%2C%20and%20design%20problems)). Instead of representing functions on a fixed grid, CORAL uses a coordinate-based MLP to encode input functions (e.g. forcing or initial conditions) into a latent vector _independent of any mesh_ ([arxiv.org](https://arxiv.org/html/2306.07266#:~:text=results%20they%20still%20face%20challenges,well%20in%20both%20convex%20and)) ([arxiv.org](https://arxiv.org/html/2306.07266#:~:text=spatio,art)). A separate neural decoder then maps that latent to the solution function values at desired coordinates. The _prompt_ here can be a combination of (a) an input function (like a heat source distribution, given as a set of sample points), and (b) a specification of the domain geometry (which can be handled by training on various shapes or encoding geometry as an additional input coordinate). During training, CORAL sees many different domains and functions, learning a latent **function space embedding**. In inference, one can feed a new shape (even one not seen before, thanks to the coordinate-based formulation) and an input field; CORAL will output the solution field. For example, for an elliptic PDE, a user could provide a point cloud of a new domain’s boundary and a spatially varying coefficient as prompts – CORAL’s neural operator will produce the solution on that domain without needing a mesh or retraining. It showed robust performance on both convex and non-convex domains, often surpassing conventional FNO or graph-based operators that struggle with geometry changes ([arxiv.org](https://arxiv.org/html/2306.07266#:~:text=limitations%2C%20we%20present%20CORAL%2C%20a,art)) ([arxiv.org](https://arxiv.org/html/2306.07266#:~:text=constraints%20on%20the%20input%20mesh%2C,art)). The key technical innovation is decoupling the operator learning from a specific mesh: any spatial sampling (even random points) can be used as input and output queries ([arxiv.org](https://arxiv.org/html/2306.07266#:~:text=limitations%2C%20we%20present%20CORAL%2C%20a,art)). This generality makes CORAL a **fully promptable operator** – geometry and resolution become inputs to the network, rather than fixed properties. The released code demonstrates solving PDEs like the Poisson equation on shapes like L-shapes, circles, etc., by simply feeding in those shape coordinates as part of the prompt.

**GAOT (Geometry-Aware Operator Transformer)** – GAOT addresses **learning PDE solution operators on arbitrary domains** by combining multiple advanced techniques ([arxiv.org](https://arxiv.org/html/2505.18781v1#:~:text=proposing%20a%20geometry%20aware%20operator,on%20a%20large%20scale%20three)). The model encodes the input (e.g. boundary conditions or source terms) on an unstructured point cloud representing the domain, using a multiscale graph neural network that is _aware of geometry_ (includes node coordinates and distances) ([arxiv.org](https://arxiv.org/html/2505.18781v1#:~:text=proposing%20a%20geometry%20aware%20operator,on%20a%20large%20scale%20three)) ([arxiv.org](https://arxiv.org/html/2505.18781v1#:~:text=operator%20encoders%20and%20decoders%2C%20together,ensure%20computational%20efficiency%20and%20scalability)). This encoding yields a latent graph representation. A Vision Transformer-like processor then operates on this latent, capturing global interactions, and finally another graph decoder outputs the solution field on the domain’s points ([arxiv.org](https://arxiv.org/html/2505.18781v1#:~:text=proposing%20a%20geometry%20aware%20operator,on%20a%20large%20scale%20three)) ([arxiv.org](https://arxiv.org/html/2505.18781v1#:~:text=operator%20encoders%20and%20decoders%2C%20together,ensure%20computational%20efficiency%20and%20scalability)). In essence, the **prompt** is the pair (domain, input function), both provided as data: the domain as a set of points or mesh elements (with coordinates), and the input function values on that set. Because of its attentional architecture, GAOT can learn to extrapolate to larger meshes or different shapes than seen in training, by focusing on the underlying geometry features. It significantly improved the trade-off between accuracy and efficiency: previous models that were accurate (e.g. some message-passing GNNs) were slow, and faster ones (like naive FNO on point clouds) were not very accurate ([arxiv.org](https://arxiv.org/html/2505.18781v1#:~:text=inputs%20into%20a%20robust%20approximation,ethz%2FGAOT)) ([arxiv.org](https://arxiv.org/html/2505.18781v1#:~:text=We%20demonstrate%20this%20significant%20gain,ethz%2FGAOT)). GAOT achieved **state-of-the-art** on several benchmarks, including a complex industry CFD dataset (likely a 3D aircraft or turbomachinery flow) where it was both more accurate _and_ faster than alternatives ([arxiv.org](https://arxiv.org/html/2505.18781v1#:~:text=We%20demonstrate%20this%20significant%20gain,ethz%2FGAOT)). From a user perspective, GAOT is promptable in that one can input any new mesh or point cloud describing a problem domain along with boundary conditions, and the model will produce a solution. The code repository, for example, shows how to prepare a CAD geometry mesh and use the trained GAOT to predict flow results on it, without needing to re-mesh or re-train for each new shape.

**PI-GANO (Physics-Informed Geometry-Aware Neural Operator)** – PI-GANO integrates **physics-informed training** with a promptable operator network that handles both varying PDE parameters and varying geometry ([arxiv.org](https://arxiv.org/html/2408.01600v1#:~:text=current%20physics,efficiency%20of%20the%20proposed%20method)). It extends DeepONet (a branch-trunk architecture) by adding a PointNet-based geometry encoder ([arxiv.org](https://arxiv.org/html/2408.01600v1#:~:text=current%20physics,efficiency%20of%20the%20proposed%20method)) ([arxiv.org](https://arxiv.org/html/2408.01600v1#:~:text=we%20introduce%20a%20novel%20method%2C,efficiency%20of%20the%20proposed%20method)). During training, instead of using a large dataset, PI-GANO uses the governing PDE equations as the training “supervisor” (a PINN approach) – it optimizes the neural operator to satisfy the PDE for all sampled parameters and geometries. The network has two branches: one takes the _PDE parameters_ (like material constants, boundary values, etc.) as input; another takes randomly sampled points on the domain as input (to encode geometry) ([arxiv.org](https://arxiv.org/html/2408.01600v1#:~:text=we%20introduce%20a%20novel%20method%2C,efficiency%20of%20the%20proposed%20method)). These branch outputs are combined to predict the solution at those points. Because it’s trained physics-informed, one model essentially learns the continuous mapping $(\text{parameters}, \text{geometry}) \mapsto \text{solution function}$ without needing labeled data. In inference, a user **prompts** the trained PI-GANO with a new geometry (provided, for instance, as a cloud of boundary points) and a set of PDE parameters. The model then rapidly produces the solution field. For example, one application in the paper is a family of Darcy flow problems: the geometry (shape of a porous medium) changes and a source term magnitude varies – PI-GANO can predict the pressure field for any new shape & source in milliseconds, whereas a FEM solver would need meshing and solving from scratch ([arxiv.org](https://arxiv.org/html/2408.01600v1#:~:text=Engineering%20design%20problems%20often%20involve,struggle%20with%20limitations%2C%20either%20in)) ([arxiv.org](https://arxiv.org/html/2408.01600v1#:~:text=Recently%2C%20machine%20learning%20techniques%20have,trained%20neural%20network%2C%20with%20minimal)). Another example is a 2D elasticity problem with different plate shapes and forces, which the model can solve across a range of cases. The accuracy is on par with direct PINN solutions, and because it learns a **generalized operator**, it can even handle geometry variations larger than those seen in training (evaluated via an extrapolation test) ([arxiv.org](https://arxiv.org/html/2408.01600v1#:~:text=2,18)) ([arxiv.org](https://arxiv.org/html/2408.01600v1#:~:text=4,18)). This model underscores that PINNs can be made promptable: once trained on a broad distribution of scenarios, no retraining is needed for each new scenario – just feed in the new problem specification.

### Text-Conditioned Physics Simulation

**Text2PDE** – Text2PDE is a cutting-edge attempt to let users **drive a physics simulation with natural language descriptions** ([arxiv.org](https://arxiv.org/html/2410.01153#:~:text=temporal%20solution%20generation%20to%20mitigate,accurate%2C%20and%20usable%20physics%20simulator)) ([arxiv.org](https://arxiv.org/html/2410.01153#:~:text=conditioning%20solely%20on%20a%20text,solvers%20closer%20to%20practical%20use)). It uses a latent diffusion model trained on diverse simulated scenarios (fluid, diffusion, waves, etc.), paired with short text captions describing the scenario. A separate encoder (like CLIP text encoder) processes the prompt text into an embedding, which conditions the diffusion model in the latent space of a mesh autoencoder ([arxiv.org](https://arxiv.org/html/2410.01153#:~:text=address%20these%20limitations%2C%20we%20introduce,for%20more%20usable%20and%20accessible)) ([arxiv.org](https://arxiv.org/html/2410.01153#:~:text=temporal%20solution%20generation%20to%20mitigate,accurate%2C%20and%20usable%20physics%20simulator)). For example, a user might input: _"Smoke ring colliding with a wall"_ – the model will generate a full 3D spatiotemporal fluid density field that fits that description. Under the hood, Text2PDE first compresses PDE simulation data (on arbitrary meshes) into a uniform latent grid via an autoencoder ([arxiv.org](https://arxiv.org/html/2410.01153#:~:text=address%20these%20limitations%2C%20we%20introduce,for%20more%20usable%20and%20accessible)). The diffusion U-Net operates on this latent representation, guided by either a text embedding or a physical initial-condition embedding (or both) ([arxiv.org](https://arxiv.org/html/2410.01153#:~:text=address%20these%20limitations%2C%20we%20introduce,for%20more%20usable%20and%20accessible)) ([arxiv.org](https://arxiv.org/html/2410.01153#:~:text=temporal%20solution%20generation%20to%20mitigate,accurate%2C%20and%20usable%20physics%20simulator)). During training, some samples are conditioned on actual physics inputs (to anchor accuracy) and some on text (to learn the language alignment). The result is a model that can interpret wording like _"high Reynolds number turbulent flow past a cylinder"_ and produce a velocity field that matches that scenario (as validated by comparing to ground-truth sim when available). Language is an imprecise prompt, so Text2PDE also allows combining text with a partial physical specification. For instance, one can supply an initial temperature field and a text prompt "… and then a hot spot appears in the corner," to generate the subsequent temperature evolution. The paper shows that prompting solely with text can yield simulations that humans find plausible and that have measurable physical correctness (the model was competitive with neural solvers given equivalent info) ([arxiv.org](https://arxiv.org/html/2410.01153#:~:text=conditioning%20solely%20on%20a%20text,solvers%20closer%20to%20practical%20use)). Importantly, the language interface makes the model far more accessible – an engineer could ask for a scenario in plain English, rather than coding boundary conditions. The authors scaled Text2PDE up to ∼3 billion parameters, finding that larger models improved both the fidelity and the adherence to the text instructions ([arxiv.org](https://arxiv.org/html/2410.01153#:~:text=generating%20physics%20simulations%2C%20paving%20the,solvers%20closer%20to%20practical%20use)). The open-source release includes examples like _“Dam break on a slope”_ where the model generates the water height field matching what one would expect. Text2PDE is a proof-of-concept that **prompt-based interfaces (like ChatGPT for physics)** are feasible, bridging the gap between descriptive intention and quantitative simulation.

### Weather and Climate Models

**FourCastNet** – FourCastNet is a prime example of a prompt-driven surrogate for global weather forecasting ([docs.nvidia.com](https://docs.nvidia.com/deeplearning/modulus/modulus-sym/user_guide/neural_operators/fourcastnet.html#:~:text=predictions%20at%200,In%20the%20current)). It was trained on 40 years of reanalysis data (ERA5), learning to predict the next 6 hours of worldwide weather given the current state. Here the **prompt** is the full 3D atmospheric state at the current time (on a 0.25° latitude-longitude grid) – essentially a stack of multichannel images of different variables ([docs.nvidia.com](https://docs.nvidia.com/deeplearning/modulus/modulus-sym/user_guide/neural_operators/fourcastnet.html#:~:text=Forecasting%20System%20%28IFS%29%2C%20a%20state,ERA5%20dataset%20at%20a%20temporal)). FourCastNet’s architecture uses a Fourier Neural Operator backbone (AFNO) to propagate this state forward in time ([docs.nvidia.com](https://docs.nvidia.com/deeplearning/modulus/modulus-sym/user_guide/neural_operators/fourcastnet.html#:~:text=the%20ERA5%20reanalysis%20dataset%20,In%20the%20current)). Crucially, one trained FourCastNet can produce forecasts for **any date or weather condition** as long as the initial state is provided. In practice, users supply a NetCDF or HDF5 file containing the initial fields (wind, temperature, pressure, etc.), and the model outputs the next time-step fields. By iteratively feeding its own output as the next prompt, FourCastNet can produce a sequence of forecasts (e.g., 1 week ahead in 6-hour increments). It runs orders of magnitude faster than traditional numerical weather prediction – a 7-day forecast can be obtained in 2 seconds on a GPU, versus hours on a supercomputer for ECMWF’s IFS ([docs.nvidia.com](https://docs.nvidia.com/deeplearning/modulus/modulus-sym/user_guide/neural_operators/fourcastnet.html#:~:text=predictions%20at%200,In%20the%20current)). Accuracy-wise, it reached parity with IFS on medium-range forecast skill for many variables ([www.huaweicloud.com](https://www.huaweicloud.com/intl/en-us/about/blogs/20230707.html#:~:text=U10%2C%20the%203,53%2C%20respectively)). For example, the model’s 5-day prediction of 500 hPa geopotential had RMSE ~10% lower than IFS in summer and comparable RMSE in winter ([www.huaweicloud.com](https://www.huaweicloud.com/intl/en-us/about/blogs/20230707.html#:~:text=times,Weather%20reduces%20them)). The open code includes _inference scripts_: one can run `python inference.py --config=afno_backbone --input_file=ERA5_2018.h5` to generate a forecast for an example initial condition ([github.com](https://github.com/NVlabs/FourCastNet#:~:text=Run%20inference%20using)). FourCastNet demonstrated that a single neural model can be prompted with any atmospheric state and produce meteorologically coherent outcomes, effectively serving as a **global weather auto-completer**.

**GraphCast** – GraphCast (by DeepMind) pushes promptable weather modeling further by using a Graph Neural Network on a geodesic grid to achieve state-of-the-art accuracy ([deepmind.google](https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting#:~:text=In%20a%20paper%20published%20in,Range%20Weather%20Forecasts%20%28ECMWF)). The model is trained to take a **graph of weather variables** at time $t$ and predict the graph at $t+6$ hours. Each node in the graph corresponds to a location on Earth (the mesh has ~80k nodes horizontally, with multiple levels vertically), carrying features like temperature, humidity, wind vectors, etc. At inference, the current observed weather (often from data assimilation) is encoded on this graph and given as the prompt to GraphCast. The message-passing network then produces the next-step graph, which can be repeated for multi-step forecasts. GraphCast achieved unprecedented accuracy – it _consistently beat ECMWF’s operational HRES model_ in test periods ([deepmind.google](https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting#:~:text=In%20a%20paper%20published%20in,Range%20Weather%20Forecasts%20%28ECMWF)). For instance, in one metric (500 hPa height anomaly correlation), GraphCast extended the skillful range by about 1–3 days compared to HRES. In more tangible terms, it better predicted extreme events like Hurricane tracks and atmospheric rivers days in advance ([deepmind.google](https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting#:~:text=GraphCast%20can%20also%20offer%20earlier,save%20lives%20through%20greater%20preparedness)) ([deepmind.google](https://deepmind.google/discover/blog/graphcast-ai-model-for-faster-and-more-accurate-global-weather-forecasting#:~:text=unprecedented%20accuracy,Range%20Weather%20Forecasts%20%28ECMWF)). The model’s GNN architecture, with attention and hierarchical updates, effectively learns the physics of the atmosphere from data. From a prompting perspective, GraphCast is versatile: one can feed it **any global state** (even from other simulation systems or climate model outputs) and it will produce the evolved state. This makes it suitable for modular use – e.g., a user could correct a forecast on-the-fly by injecting new observations as the prompt at a later time. The GraphCast code release provides pre-trained weights and a Colab notebook that shows how to load an initial condition (ERA5 reanalysis for a specific date) and run the model to predict the next frames ([github.com](https://github.com/google-deepmind/graphcast#:~:text=Colaboratory%2C%20which%20gives%20an%20example,and%20the)). It’s essentially _“plug-and-play” weather simulation_: the heavy training is done, and inference is just feeding in data through the graph model. GraphCast also introduced **GenCast**, a diffusion-based ensemble generator, in the same package ([github.com](https://github.com/google-deepmind/graphcast#:~:text=a%20free%20Colab%20notebook%29,Mini%20only%20uses%208%20member)) – using a small diffusion model to stochastically perturb GraphCast’s deterministic output and produce probabilistic forecasts (another form of prompt controlling output uncertainty). Overall, GraphCast demonstrates that foundation models can exist in physical domains, where the prompt is the entire state of a complex system.

**Pangu-Weather** – Pangu-Weather is another notable prompt-driven weather model, developed by Huawei. It uses a 3D U-Net + Vision Transformer hybrid to forecast global weather at 0.25° resolution ([www.researchgate.net](https://www.researchgate.net/figure/Pangu-Weather-produces-higher-accuracy-than-the-operational-IFS-and-FourCastNet-in_fig2_372137432#:~:text=Download%20Scientific%20Diagram%20www,NWP%29%20method%2C%20which)). The user’s prompt is the 3D atmospheric state (similar to FourCastNet’s input). Pangu’s novelty is splitting the forecast into sequential stages (3-hour, 6-hour, etc., each with its own network), but from a usage perspective it functions as one model that you feed today’s weather and it gives tomorrow’s prediction. Pangu-Weather was the first AI model to _exceed the accuracy of ECMWF_’s operational model on some metrics ([www.huaweicloud.com](https://www.huaweicloud.com/intl/en-us/about/blogs/20230707.html#:~:text=Pangu,06)). For example, for 5-day forecasts of Z500 (500 mb geopotential height), Pangu achieved RMSE of 296.7 m^2/s^2 vs 333.7 for IFS (lower is better) ([www.huaweicloud.com](https://www.huaweicloud.com/intl/en-us/about/blogs/20230707.html#:~:text=times,Weather%20reduces%20them)). It also improved 10m wind and 850mb temperature forecasts significantly ([www.huaweicloud.com](https://www.huaweicloud.com/intl/en-us/about/blogs/20230707.html#:~:text=times,Weather%20reduces%20them)). These results, published in _Nature_, validated that deep learning surrogates can match decades of NWP development. However, Pangu’s code/weights were not immediately shared publicly (it’s used internally and via cloud API), so unlike FourCastNet or GraphCast, external users cannot freely run it themselves. Still, conceptually, if one had the Pangu model, using it is as straightforward as other promptable surrogates: ingest the current ERA5 weather cube and run the network forward. The success of Pangu (and GraphCast) underscores an important point: _the same trained model can generalize to essentially infinitely many “scenarios” (weather patterns), conditioned only on the present state as input_. This is precisely the “promptable” quality needed – no retraining per new weather event.

### Other Domains

**InverseDiffusion for Elastography (Dasgupta et al. 2024)** – This work applies conditional diffusion to an **inverse problem in solid mechanics** ([arxiv.org](https://arxiv.org/html/2406.13154v1#:~:text=We%20propose%20a%20framework%20to,Monte%20Carlo%20scheme%20based%20on)). The task is to infer the spatial distribution of a material property (e.g. elastic modulus in a biological tissue) from externally measured deformation data (e.g. surface displacements or strain fields). The model uses a _score-based diffusion network_ conditioned on the measured response field ([arxiv.org](https://arxiv.org/html/2406.13154v1#:~:text=based%20diffusion%20models%20to%20solve,Monte%20Carlo%20scheme%20based%20on)). At inference, the **prompt** is a set of observed mechanical responses (which could be an image of a deformed sample or a sparse set of displacement vectors), and the model generates samples of possible internal property fields (like maps of where a tumor might be stiffer) ([arxiv.org](https://arxiv.org/html/2406.13154v1#:~:text=based%20diffusion%20models%20to%20solve,Monte%20Carlo%20scheme%20based%20on)) ([arxiv.org](https://arxiv.org/html/2406.13154v1#:~:text=forward%20model,approach%20can%20handle%20different%20measurement)). Because the problem is ill-posed (many distributions can explain the measurements), a diffusion model is ideal to capture the posterior distribution. Technically, they train the score network by simulating many random heterogeneous materials and their resulting mechanical responses (via a forward FEM), then learn to map a response + noise → gradient of the likelihood of a material property field ([arxiv.org](https://arxiv.org/html/2406.13154v1#:~:text=from%20noisy%20measurements%20of%20its,Monte%20Carlo%20scheme%20based%20on)) ([arxiv.org](https://arxiv.org/html/2406.13154v1#:~:text=score%20function%20of%20a%20conditional,Monte%20Carlo%20scheme%20based%20on)). The physics (governing elasticity PDE) is embedded in the training data rather than explicitly in the model. When a new measurement comes in, one simply feeds it to the trained network (no retraining) and runs Langevin sampling to get possible material property maps that align with the measurement. The authors demonstrated this on synthetic elastography data, successfully localizing hidden inclusions and reconstructing complex spatial patterns that classical optimization or PINNs had trouble with (especially under noisy, limited data) ([arxiv.org](https://arxiv.org/html/2406.13154v1#:~:text=forward%20model,approach%20can%20handle%20different%20measurement)). The prompt-to-output pipeline here essentially turns a single pre-trained model into an on-demand inverse solver for any new specimen – a task that normally would require setting up and solving a computationally intensive inverse problem for each case. This represents a new level of **promptability in inverse design/diagnosis**: the model acts like a _medical expert_ that immediately proposes likely internal structures upon seeing external measurements, thanks to its diffusion-based learned prior.

**Parnassus (Generative Fast Detector Simulation)** – In high-energy physics, _Parnassus_ is a project that uses conditional generative models to **simulate particle detector events** much faster than Geant4 simulations. The 2025 extension by Dreyer et al. allows prompting entire LHC events through their _particle-flow representation_ ([arxiv.org](https://arxiv.org/html/2503.19981v1#:~:text=We%20extend%20the%20Particle,compatible.%20Using%20a)). The prompt in this case is a list of “truth particles” produced in a simulated collision (their types, energies, trajectories). Parnassus then uses a **normalizing flow and diffusion model ensemble** to generate the list of “reconstructed” particles that a detector would register ([arxiv.org](https://arxiv.org/html/2503.19981v1#:~:text=fast%20simulation%20and%20reconstruction%20to,compatible.%20Using%20a)) ([arxiv.org](https://arxiv.org/html/2503.19981v1#:~:text=normalizing%20flows%20and%20diffusion%20models%2C,the%20standard%2C%20public%20tool%20Delphes)). Essentially, it’s translating ideal physics output into realistic detector output, including complexities of detector noise, inefficiencies, and combinatorics – all as a learned stochastic transformation. At runtime, a physicist can input any new physics event (e.g. from a different process or new theory) described by its particles, and the model will rapidly produce a realistic mock detector reading (particle-flow objects) without running the slow detector simulation programs ([arxiv.org](https://arxiv.org/html/2503.19981v1#:~:text=accommodate%20all%20particle,the%20standard%2C%20public%20tool%20Delphes)). Technically, they condition both a continuous normalizing flow and a score-based diffusion on the truth particles’ kinematic features ([arxiv.org](https://arxiv.org/html/2503.19981v1#:~:text=fast%20simulation%20and%20reconstruction%20to,compatible.%20Using%20a)) to output a set of reconstructed particles. The architecture accommodates variable-length inputs/outputs by modeling events as sets. The results showed better accuracy than the standard FastSim tool (Delphes) in reproducing high-level observables, and importantly, the model generalized well to physics processes not seen in training (owing to the fact it was trained on a mixture of many processes) ([arxiv.org](https://arxiv.org/html/2503.19981v1#:~:text=accommodate%20all%20particle,the%20standard%2C%20public%20tool%20Delphes)). This means the same model can simulate “QCD jets”, “top quark decays”, even potentially new exotic signals, as long as you feed in the appropriate truth particles. Parnassus embodies promptability in a domain where traditionally each new scenario (new physics model or detector) would require significant manual tuning – here it’s _“Condition on truth, generate detector output”_. The code release allows users to plug in custom particle lists (formatted as needed) and sample detector events via a simple Python API, making it a powerful tool for the collider physics community.

## c. Gaps & Opportunities for Fully Promptable Physics Models

- **Multi-Physics & Coupled Systems** – There is a lack of _unified models_ that handle coupled physics (e.g. fluid-structure interaction, plasma-fluid coupling) in a promptable way. Current models focus on one domain at a time. An opportunity is to train generative networks on coupled simulations so that a single model can be prompted with, say, a structural geometry _and_ a flow condition and output both the fluid and structural response.

- **General-Purpose Physics Foundation Model** – We are still missing a “GPT of physics” that can take an arbitrary physics problem description (PDE, geometry, initial/boundary conditions described in text or code) and return a solution or field. This would require combining symbolic understanding (to parse equations or verbal descriptions) with numeric prediction – an open research frontier.

- **Prompting Physical Constraints** – Current promptable models often rely on learning to enforce physics; however, there's an opportunity for allowing _constraints as part of the prompt_. For example, one could prompt a model “generate a flow field that satisfies mass conservation and has a vortex in the top-right”. Developing interfaces to impose hard physical laws or symmetries during generation is an open problem.

- **Adaptive Resolution and Domain** – Fully promptable simulators should allow users to specify resolution, domain size, or fidelity at inference time. Today’s models are usually trained at fixed resolution. A gap exists in models that can _zoom_ or _coarsen_ results on the fly based on prompt instructions, which would be valuable for multi-scale problems.

- **Data Efficiency and Extrapolation** – Many models struggle if prompted outside the training distribution (e.g. much higher Reynolds number or completely new geometry). Developing promptable models that can _extrapolate_ or that can accept a prompt plus a small calibration dataset (few-shot learning for physics) is an open challenge. Meta-learning or combining with analytical solutions might help here.

- **Interactive and Iterative Prompting** – Current approaches assume a one-shot prompt (provide all conditions, get result). An opportunity is interactive simulators where a user can iteratively refine the prompt (e.g. “make that boundary a bit hotter and rerun”) without full retraining. Mechanisms for fast conditional re-simulation or editing the output field based on new prompts would increase usefulness.

- **Uncertainty Quantification Integration** – While some models (diffusion-based) provide ensembles, there's a gap in seamlessly integrating uncertainty prompts. For instance, one might want to ask “give me a high-probability outcome vs a low-probability extreme outcome” as a prompt. Future models could allow controlling the randomness or confidence of outputs via the prompt (like guiding the diffusion temperature).

- **Benchmarking and Standardization** – The field lacks standardized benchmarks to evaluate promptable physics models across scenarios. Establishing open datasets and prompt tasks (analogous to GLUE in NLP) would help identify gaps. For example, a benchmark could ask models to solve a set of PDEs with varying prompts. This would clarify where current models fail (e.g. perhaps complex boundary topologies or very long temporal extrapolation).

- **Accessibility and Interfaces** – Finally, an opportunity is building user-friendly interfaces (e.g. prompt languages or GUIs) for these models. Much like ChatGPT made language AI accessible, a similar interface for physics (maybe combining text and diagrams as prompts) is missing. Developing a “Physics Copilot” that interprets user intent (in natural language or simple code) and invokes the right promptable model could democratize simulation. None of the current models fully addresses this yet, as they remain research codes.

## d. Appendix
